from __future__ import print_function
from imutils.object_detection import non_max_suppression
from imutils.video import FileVideoStream
from imutils.video import FPS
from imutils import paths
import numpy as np
import argparse
import imutils
import time
import cv2

# construct the argument parse and parse the arguments
ap = argparse.ArgumentParser()
ap.add_argument("-v", "--video", required=True,
	help="path to input video file")
args = vars(ap.parse_args())

# start the file video stream thread and allow the buffer to
# start to fill
print("[INFO] starting video file thread...")
fvs = FileVideoStream(args["video"]).start()
time.sleep(1.0)

# start the FPS timer
fps = FPS().start()

#our trained classifiers
car_tracker_file = 'cars.xml'
pedstrain_tracker_file ='fullbody.xml'

#car and pedstrain  classifier 
car_tracker= cv2.CascadeClassifier(car_tracker_file)
pedstrain_tracker= cv2.CascadeClassifier(pedstrain_tracker_file)

hog = cv2.HOGDescriptor() 
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector()) 

count =0
skipframe =1
# loop over frames from the video file stream
while fvs.more():
	count+=1
	# grab the frame from the threaded video file stream, resize
	# it, and convert it to grayscale (while still retaining 3   
	# channels)
	

	frame = fvs.read()


	frame = imutils.resize(frame, width=min(720, frame.shape[1]))
	frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
	frame = np.dstack([frame, frame, frame])
	(pedestrain, _) = hog.detectMultiScale(frame, winStride=(4, 4), padding=(8, 8), scale=1.05) 
    
	cars = car_tracker.detectMultiScale(frame)
	person = 1
	
	for (x, y, w, h) in pedestrain: 
			cv2.rectangle(frame, (x, y), (x + w, y + h),  (0, 255, 0), 2) 
			cv2.putText(frame, f'person {person}', (x,y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)
			person +=1
	# apply non-maxima suppression to the bounding boxes using a
	# fairly large overlap threshold to try to maintain overlapping
	# boxes that are still people
	pedestrain = np.array([[x, y, x + w, y + h] for (x, y, w, h) in pedestrain])
	pick = non_max_suppression(pedestrain, probs=None, overlapThresh=0.65)
	# draw the final bounding boxes
	for (xA, yA, xB, yB) in pick:
		cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 255, 0), 2)		

	for (x,y,w,h) in cars:
		cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)	 
		car_array = np.array([[x, y, x + w, y + h] for (x, y, w, h) in cars]) 
		#pick_car= non_max_suppression(cars, probs=None, overlapThresh=0.65)
	for (xA, yA, xB, yB) in cars:
		cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 0, 255), 2)

    		


	# display the size of the queue on the frame
	cv2.putText(frame, "Queue Size: {}".format(fvs.Q.qsize()),
		(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)	
		
    #show number of detected persons
	cv2.putText(frame, f'Total Persons : {person-1}', (10,10), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255,0,0), 2)
	# show the frame and update the FPS counter
	cv2.imshow("Frame",frame)
	cv2.waitKey(1)
	fps.update()
		
	
    
	# stop the timer and display FPS information
	fps.stop()
	print("[INFO] elasped time: {:.2f}".format(fps.elapsed()))
	print("[INFO] approx. FPS: {:.2f}".format(fps.fps()))

# do a bit of cleanup
cv2.destroyAllWindows()
fvs.stop()	
